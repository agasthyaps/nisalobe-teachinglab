# CAP Overview: Structure, Purpose, and Exemplars

## What is a CAP?

A **Coaching Action Plan (CAP)** is Teaching Lab's structured planning and documentation tool for instructional coaching. It serves as a living document that tracks coaching cycles, aligns coaching moves to teacher goals, and captures observable evidence of impact on both teacher practice and student learning.

The CAP exists in three models:
- **1:1 Coaching**: One coach working with one teacher across multiple cycles
- **Group Coaching**: One coach working with a group of teachers (average data recorded)
- **Leader Coaching**: Coaching for school or district leaders

## Core Structure

### Cycles and Sessions
- CAPs are organized by **cycles** (Cycle 1, Cycle 2, etc.), with each cycle containing multiple coaching sessions
- Standard cycle: **6 sessions** (can be extended with additional session tabs)
- Each cycle builds on previous work toward a common goal

### Key Components

#### 1. **Area of Focus**
The problem of practice being addressed, with clear rationale.
- **What to include:** Observable evidence from classroom or teacher practice that identifies the gap
- **Why it matters:** Connection between the observed issue and its impact on instruction or student learning
- **Clarity indicator:** The problem of practice should be unmistakable to any reader

#### 2. **Goal**
The specific, measurable target the teacher is working toward during this cycle.

#### 3. **Metrics - Observable Evidence of Impact**
Concrete indicators that show progress, divided into:

**Teacher Metrics:**
- Specific teacher actions being tracked
- Evidence sources (e.g., lesson plans, observation notes, teacher-collected data)
- Frequency of data collection (weekly, bi-weekly, etc.)

**Student Metrics:**
- Quantified expectations (e.g., "65%+ of students demonstrate...")
- Named measurement tools or assessments
- Observable student behaviors or outcomes

#### 4. **Menu of Coaching Moves**
A library of ~10 coaching moves the coach plans to use during the cycle.
- Each **row** = one coaching move (not one session)
- Moves must be listed here to appear in decision log dropdowns
- Should align to the goal
- **Technical note:** Avoid punctuation (commas, apostrophes) in move descriptions to prevent dropdown validation errors

#### 5. **Decision Log**
Session-by-session record linking coaching moves to specific visits.
- Coaches can tag **multiple moves per session**
- Documents which moves from the menu were deployed when

#### 6. **Session Documentation**
For each session, capture:
- **Teacher actions:** What actions did you take with the teacher?
- **Student outcomes:** What was the observable impact on student learning?
- **Next steps:** What is the teacher trying before the next visit? What should on-site support (admin) do to reinforce?
- **Rationale:** Why did you rate the metrics this way? Connect coaching actions to teacher and student growth.
- **Planned for Instruction:** Includes micro-PL moments (modeling strategies, unpacking lessons)

## How to Use the CAP

### Before Starting
1. Create and name the CAP according to coaching model conventions
2. Authorize the CAP by running Admin dropdown scripts
3. Store in correct shared drive folder (not as shortcut, not in subfolders)

### During Coaching
1. **Cycle Planning:** Define area of focus, goal, and metrics at cycle start
2. **Build the Menu:** Populate 8-10 coaching moves aligned to the goal
3. **Session-by-Session:** After each visit, document teacher actions, student outcomes, next steps, and rationale
4. **Track Progress:** Tag which coaching moves were used via decision log

### Between Cycles
- Review metrics and outcomes from completed cycle
- Determine if new cycle continues same goal or pivots to new area of focus
- Create new cycle tab (e.g., Cycle 2) in same CAP file if teacher/group composition remains similar
- For significant roster or goal changes, create new CAP

### Data Integrity Requirements
- Do **not** alter CAP layout (adding columns, moving sections)
- Name tabs exactly as modeled: "Cycle 1", "Cycle 2"
- Delete test/dummy CAPs to keep dashboard clean
- Use master survey input for exact name spelling

## Exemplar Entries

### Exemplar: Area of Focus
**What makes it strong:**
- Uses **concrete, quantified evidence** (e.g., "0 of 12 students verbalized during writing tasks")
- Clearly **names the gap** in observable terms
- Explains **why it matters** by connecting to instructional decision-making or student learning
- Makes the problem of practice **unmistakable** to any reader

**Example structure:**
> "During independent writing, 0 of 12 students verbalized their thinking when prompted. This limits the teacher's ability to formatively assess student understanding and make in-the-moment instructional adjustments. By increasing individual student 'at-bats' for verbalization, the teacher will gather more accurate data on student mastery and be able to differentiate support accordingly."

### Exemplar: Metrics - Observable Evidence of Impact

**Teacher Metrics - What makes them strong:**
- Identify **specific actions** (e.g., "tracks accuracy data weekly")
- Name **evidence sources** (e.g., "oral checks during guided practice, written exit tickets")
- Specify **frequency** (weekly, daily, per lesson)

**Example:**
> "Teacher will collect and analyze student accuracy data weekly using oral comprehension checks during guided reading and written responses on exit tickets."

**Student Metrics - What makes them strong:**
- **Quantify expectations** (e.g., "65%+ of students demonstrate accuracy")
- Name the **tool or method** used to measure (e.g., "as measured by weekly quiz scores")
- Describe **observable student behavior** or outcome

**Example:**
> "65%+ of students will demonstrate accuracy in identifying text evidence to support inferences, as measured by weekly reading response tasks."

### Exemplar: Session Documentation - Rationale

**What makes it strong:**
- Tells the **story** of your coaching impact
- Connects **coaching actions** → **teacher actions** → **student outcomes**
- Explains the **logic** behind metric ratings
- Specific enough that another coach could understand the progression

**Example structure:**
> "I modeled how to use a think-aloud during shared reading, then co-taught a lesson where the teacher practiced this move with half the class. Students responded with 8/12 verbalizing their thinking (up from 0/12 baseline), demonstrating immediate impact. Teacher will continue practicing think-alouds during all shared reading lessons this week, with admin observing one lesson to provide reinforcement feedback."

## Common Pitfalls to Avoid

- **Vague Area of Focus:** "Students need to improve reading" → Too broad, no observable evidence
- **Unmeasurable Metrics:** "Teacher will improve questioning" → What does improvement look like? How measured?
- **Menu formatting:** Using punctuation in coaching move descriptions causes dropdown errors
- **Layout changes:** Adding rows/columns breaks dashboard sync
- **Missing authorization:** Dropdowns show REF errors when authorization steps skipped
- **Test CAPs:** Dummy CAPs pollute dashboard data; delete after testing

## Quick Reference: CAP Workflow

1. **Create** → Name correctly, authorize, store in shared drive
2. **Plan Cycle** → Area of focus + goal + metrics + menu of moves
3. **Document Sessions** → Teacher actions, student outcomes, next steps, rationale
4. **Track Moves** → Tag moves in decision log
5. **Review Progress** → Assess metrics, determine next cycle focus
6. **Repeat** → New cycle tab in same CAP (unless major changes)

---

Use this overview to understand CAP purpose, structure, and quality standards. Reference exemplars when coaching staff on writing clear, actionable CAP entries.
